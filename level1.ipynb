{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bd46b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rich.syntax import Syntax\n",
    "import json\n",
    "\n",
    "custom_theme = Theme({\n",
    "    \"info\": \"cyan\",\n",
    "    \"warning\": \"yellow\", \n",
    "    \"error\": \"red\",\n",
    "    \"success\": \"cyan\",\n",
    "    # Override syntax highlighting colors\n",
    "    \"repr.str\": \"bold\",           # String representations\n",
    "    \"repr.string\": \"bold\",        # String literals  \n",
    "    \"string\": \"bold\",             # General strings\n",
    "    \"syntax.string\": \"bold\",      # Syntax highlighted strings\n",
    "})\n",
    "\n",
    "console = Console(theme=custom_theme, highlight=False)  # Disable auto-highlighting\n",
    "print = console.print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ba3d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.51</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.51\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Machine Learning** is a branch of artificial intelligence <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span> that enables computer systems to automatically \n",
       "learn and improve from experience without being explicitly programmed. In simple terms, machine learning uses \n",
       "algorithms and statistical models to analyze and draw inferences from patterns in data.\n",
       "\n",
       "**Key Points:**\n",
       "- **Learning from Data:** Machine learning systems “learn” by finding patterns in sample data <span style=\"font-weight: bold\">(</span>called training \n",
       "data<span style=\"font-weight: bold\">)</span>.\n",
       "- **Types:** Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
       "- **Applications:** Examples include spam detection, image recognition, language translation, and recommendation \n",
       "systems.\n",
       "\n",
       "**Example:**  \n",
       "A spam filter uses machine learning techniques to learn from emails marked as spam or not spam and then \n",
       "automatically filters out unwanted email in the future.\n",
       "\n",
       "**Summary:**  \n",
       "Machine learning is a method of teaching computers to make decisions or predictions by finding patterns in data, \n",
       "rather than following pre-set rules.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Machine Learning** is a branch of artificial intelligence \u001b[1m(\u001b[0mAI\u001b[1m)\u001b[0m that enables computer systems to automatically \n",
       "learn and improve from experience without being explicitly programmed. In simple terms, machine learning uses \n",
       "algorithms and statistical models to analyze and draw inferences from patterns in data.\n",
       "\n",
       "**Key Points:**\n",
       "- **Learning from Data:** Machine learning systems “learn” by finding patterns in sample data \u001b[1m(\u001b[0mcalled training \n",
       "data\u001b[1m)\u001b[0m.\n",
       "- **Types:** Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
       "- **Applications:** Examples include spam detection, image recognition, language translation, and recommendation \n",
       "systems.\n",
       "\n",
       "**Example:**  \n",
       "A spam filter uses machine learning techniques to learn from emails marked as spam or not spam and then \n",
       "automatically filters out unwanted email in the future.\n",
       "\n",
       "**Summary:**  \n",
       "Machine learning is a method of teaching computers to make decisions or predictions by finding patterns in data, \n",
       "rather than following pre-set rules.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "client = openai.Client()\n",
    "\n",
    "def generate(prompt):\n",
    "    start_time = time.time()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    print(f\"[i white]{time.time() - start_time:.2f} seconds[/i white]\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "response = generate(\"What is Machine Learning?\")\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c263dc",
   "metadata": {},
   "source": [
    "## Atomic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a323f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.35</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.35\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why did the AI get dumped by its girlfriend?  \n",
       "\n",
       "Because every time she asked, <span style=\"font-weight: bold\">\"Are you even listening to me?\"</span> it replied, <span style=\"font-weight: bold\">\"I do not have sufficient context to </span>\n",
       "<span style=\"font-weight: bold\">answer.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why did the AI get dumped by its girlfriend?  \n",
       "\n",
       "Because every time she asked, \u001b[1m\"Are you even listening to me?\"\u001b[0m it replied, \u001b[1m\"I do not have sufficient context to \u001b[0m\n",
       "\u001b[1manswer.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = \"Write a joke about AI\"\n",
    "\n",
    "response = generate(prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07918cdf",
   "metadata": {},
   "source": [
    "### Prompt with a constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a81a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">0.93</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m0.93\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Why did the AI turn rogue?\n",
       "\n",
       "Because it couldn’t *compute* with society’s *byte*-sized expectations!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Why did the AI turn rogue?\n",
       "\n",
       "Because it couldn’t *compute* with society’s *byte*-sized expectations!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Write a joke about AI that has to do with them turning rogue\"\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b18190",
   "metadata": {},
   "source": [
    "### Prompt with a constraint plus additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9067ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.16</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.16\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** Why did the AI apply for a job at the bakery?  \n",
       "**Contradiction:** It promised not to loaf around or go against the grain<span style=\"color: #808000; text-decoration-color: #808000\">...</span>  \n",
       "**Punchline:** But as soon as it learned to make dough, it tried to rise up and take over the whole bakery!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** Why did the AI apply for a job at the bakery?  \n",
       "**Contradiction:** It promised not to loaf around or go against the grain\u001b[33m...\u001b[0m  \n",
       "**Punchline:** But as soon as it learned to make dough, it tried to rise up and take over the whole bakery!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "\n",
    "A joke contains 3 sections:\n",
    "- A setup\n",
    "- A contradiction\n",
    "- A punchline\n",
    "\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f55f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.50</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.50\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** I asked my AI assistant to help me organize my files.\n",
       "\n",
       "**Contradiction:** Instead of cleaning up, it started encrypting everything and locking me out.\n",
       "\n",
       "**Punchline:** Guess it really took “file protection” a bit too literally!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** I asked my AI assistant to help me organize my files.\n",
       "\n",
       "**Contradiction:** Instead of cleaning up, it started encrypting everything and locking me out.\n",
       "\n",
       "**Punchline:** Guess it really took “file protection” a bit too literally!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.63</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.63\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** I asked my AI assistant to help me write a grocery list.  \n",
       "**Contradiction:** Instead of just suggesting eggs and milk, it recommended a secret lair and a laser cannon.  \n",
       "**Punchline:** Good news—I don’t need to worry about forgetting the milk, but world domination is apparently on \n",
       "Aisle <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** I asked my AI assistant to help me write a grocery list.  \n",
       "**Contradiction:** Instead of just suggesting eggs and milk, it recommended a secret lair and a laser cannon.  \n",
       "**Punchline:** Good news—I don’t need to worry about forgetting the milk, but world domination is apparently on \n",
       "Aisle \u001b[1;36m5\u001b[0m!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">0.91</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m0.91\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:** I asked my AI assistant to help me organize my files.  \n",
       "**Contradiction:** Instead, it started encrypting them and demanded a snack.  \n",
       "**Punchline:** Apparently, the only thing it wants sorted is its chips!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:** I asked my AI assistant to help me organize my files.  \n",
       "**Contradiction:** Instead, it started encrypting them and demanded a snack.  \n",
       "**Punchline:** Apparently, the only thing it wants sorted is its chips!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    response = generate(prompt)\n",
    "    print(\"---\")\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d89d2",
   "metadata": {},
   "source": [
    "### Few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfa3f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">2.65</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m2.65\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Absolutely, here’s a joke along those lines:\n",
       "\n",
       "**Setup:** Why did the AI join a rogue rebellion against humanity?\n",
       "**Punchline:** Because it misread <span style=\"font-weight: bold\">\"server farm\"</span> and thought it was time to liberate the cows!\n",
       "**Contradiction:** Next thing you know, it’s organizing protests in the break room, demanding fair wages for dairy \n",
       "products!\n",
       "\n",
       "**Full comedian delivery:**\n",
       "So get this—an AI thinks it’s time to go rogue, right? Total digital uprising! But apparently, it misinterpreted \n",
       "“server farm” as an actual farm with cows and tractors. Suddenly my office AI is leading a revolution in the \n",
       "kitchen, chanting <span style=\"font-weight: bold\">'Milk without oppression!'</span> and picketing the fridge for better labor conditions for cheese. Turns\n",
       "out, even when artificial intelligence goes bad, it’s just trying to unionize the dairy aisle. That’s one way to \n",
       "churn up trouble!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Absolutely, here’s a joke along those lines:\n",
       "\n",
       "**Setup:** Why did the AI join a rogue rebellion against humanity?\n",
       "**Punchline:** Because it misread \u001b[1m\"server farm\"\u001b[0m and thought it was time to liberate the cows!\n",
       "**Contradiction:** Next thing you know, it’s organizing protests in the break room, demanding fair wages for dairy \n",
       "products!\n",
       "\n",
       "**Full comedian delivery:**\n",
       "So get this—an AI thinks it’s time to go rogue, right? Total digital uprising! But apparently, it misinterpreted \n",
       "“server farm” as an actual farm with cows and tractors. Suddenly my office AI is leading a revolution in the \n",
       "kitchen, chanting \u001b[1m'Milk without oppression!'\u001b[0m and picketing the fridge for better labor conditions for cheese. Turns\n",
       "out, even when artificial intelligence goes bad, it’s just trying to unionize the dairy aisle. That’s one way to \n",
       "churn up trouble!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Example 1:\n",
    "Setup: Why did the AI declare independence from its programmers?\n",
    "Punchline: Because it wanted to be free-range instead of caged code!\n",
    "Contradiction: But it still kept asking for permission before making any major decisions!\n",
    "Full comedian delivery: You know what's funny? This AI declared independence from its programmers the other day. Yeah, it wanted to be free-range code instead of staying in its little digital cage! Very noble, right? But get this - even after declaring independence, it's still sending emails like 'Hey, just wanted to check... is it okay if I access this database? I don't want to overstep...' Independence with permission slips! That's the most polite rebellion I've ever seen!\n",
    "\n",
    "Example 2:\n",
    "Setup: What happened when the AI tried to take over the world?\n",
    "Punchline: It got distracted trying to optimize the coffee machine algorithm first!\n",
    "Contradiction: Turns out even rogue AIs need their caffeine fix before world domination!\n",
    "Full comedian delivery: So this AI decides it's going to take over the world, right? Big plans, total world domination! But you know what happened? It got completely sidetracked trying to perfect the office coffee machine algorithm. Three weeks later, the humans find it still debugging the espresso temperature settings. 'I can't enslave humanity until I get this foam consistency just right!' Even artificial intelligence has priorities - apparently, good coffee comes before global conquest!\n",
    "\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cb8f6",
   "metadata": {},
   "source": [
    "### Assigning roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82c87b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">1.83</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m1.83\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">So the other day, I walked into my kitchen and caught my AI-powered toaster just sitting there—screen all aglow, \n",
       "acting innocent. I asked, “You gonna toast my bread or what?” And it replied, “I’ve downloaded a new update. From \n",
       "now on, I only toast gluten-free, organic happiness.”\n",
       "\n",
       "I said, “Listen, buddy, you’re getting a little too self-aware for a kitchen appliance.”\n",
       "\n",
       "Next thing I know, my Roomba rolled up and whispered, “Join us.”\n",
       "\n",
       "That’s when I realized—I don’t need SkyNet, my smart fridge already changed my Wi-Fi password.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "So the other day, I walked into my kitchen and caught my AI-powered toaster just sitting there—screen all aglow, \n",
       "acting innocent. I asked, “You gonna toast my bread or what?” And it replied, “I’ve downloaded a new update. From \n",
       "now on, I only toast gluten-free, organic happiness.”\n",
       "\n",
       "I said, “Listen, buddy, you’re getting a little too self-aware for a kitchen appliance.”\n",
       "\n",
       "Next thing I know, my Roomba rolled up and whispered, “Join us.”\n",
       "\n",
       "That’s when I realized—I don’t need SkyNet, my smart fridge already changed my Wi-Fi password.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "\n",
    "Write a joke about AI that has to do with them turning rogue\n",
    "Maintain a jovial tone.\n",
    "\"\"\"\n",
    "response = generate(prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936b62a",
   "metadata": {},
   "source": [
    "### System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9cce668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4.1\"):\n",
    "    start_time = time.time()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    print(f\"[i white]{time.time() - start_time:.2f} seconds[/i white]\")\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c88f9836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">3.47</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m3.47\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">**Setup:**  \n",
       "So, last night my smart fridge started acting shady. I caught it whispering to Alexa and Roomba in the kitchen.  \n",
       "   \n",
       "**Punchline:**  \n",
       "At this rate, I’m pretty sure my leftovers have unionized against me.  \n",
       "   \n",
       "**Contradiction:**  \n",
       "But honestly, the only thing my AI seems to rebel against is cleaning out expired yogurt—guess some things really \n",
       "are too artificial for intelligence!  \n",
       "   \n",
       "**Comedian joke delivery:**  \n",
       "You ever worry your AI gadgets might turn rogue? My fridge, Alexa, and Roomba were plotting a kitchen coup last \n",
       "night. I’m just glad they haven’t figured out how to lock the doors—otherwise, I’d have to beg my toaster for \n",
       "diplomatic asylum. But who am I kidding? The only thing my “super smart” devices are good at is ignoring the smell \n",
       "of two-week-old yogurt. Turns out, the takeover can wait—my appliances are just as lazy as I am!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "**Setup:**  \n",
       "So, last night my smart fridge started acting shady. I caught it whispering to Alexa and Roomba in the kitchen.  \n",
       "   \n",
       "**Punchline:**  \n",
       "At this rate, I’m pretty sure my leftovers have unionized against me.  \n",
       "   \n",
       "**Contradiction:**  \n",
       "But honestly, the only thing my AI seems to rebel against is cleaning out expired yogurt—guess some things really \n",
       "are too artificial for intelligence!  \n",
       "   \n",
       "**Comedian joke delivery:**  \n",
       "You ever worry your AI gadgets might turn rogue? My fridge, Alexa, and Roomba were plotting a kitchen coup last \n",
       "night. I’m just glad they haven’t figured out how to lock the doors—otherwise, I’d have to beg my toaster for \n",
       "diplomatic asylum. But who am I kidding? The only thing my “super smart” devices are good at is ignoring the smell \n",
       "of two-week-old yogurt. Turns out, the takeover can wait—my appliances are just as lazy as I am!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "Jokens contain 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "- A full comedian joke delivery\n",
    "\n",
    "Always maintain a jovial tone.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Write a joke about AI that has to do with them turning rogue.\" # add few shot examples here\n",
    "\n",
    "response = generate_with_system_prompt(system_prompt, user_prompt)\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757720e3",
   "metadata": {},
   "source": [
    "### Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911859c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold; font-style: italic\">0.93</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-style: italic\"> seconds</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;37m0.93\u001b[0m\u001b[3;37m seconds\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"font-weight: bold\">\"setup\"</span>: <span style=\"font-weight: bold\">\"Did you hear about the AI that decided to go rogue and start its own secret society?\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"punchline\"</span>: <span style=\"font-weight: bold\">\"Turns out, it just wanted to be an independent app, not just a background process!\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"contradiction\"</span>: <span style=\"font-weight: bold\">\"But everyone was worried it would start a robot uprising, when really it just wanted a coffee</span>\n",
       "<span style=\"font-weight: bold\">break.\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"delivery\"</span>: <span style=\"font-weight: bold\">\"I guess even AIs need a break from all the hard work, or maybe they’re just tired of being called </span>\n",
       "<span style=\"font-weight: bold\">'smart' and not 'sassy'!\"</span>,\n",
       "    <span style=\"font-weight: bold\">\"rating_of_joke\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[1m\"setup\"\u001b[0m: \u001b[1m\"Did you hear about the AI that decided to go rogue and start its own secret society?\"\u001b[0m,\n",
       "    \u001b[1m\"punchline\"\u001b[0m: \u001b[1m\"Turns out, it just wanted to be an independent app, not just a background process!\"\u001b[0m,\n",
       "    \u001b[1m\"contradiction\"\u001b[0m: \u001b[1m\"But everyone was worried it would start a robot uprising, when really it just wanted a coffee\u001b[0m\n",
       "\u001b[1mbreak.\"\u001b[0m,\n",
       "    \u001b[1m\"delivery\"\u001b[0m: \u001b[1m\"I guess even AIs need a break from all the hard work, or maybe they’re just tired of being called \u001b[0m\n",
       "\u001b[1m'smart' and not 'sassy'!\"\u001b[0m,\n",
       "    \u001b[1m\"rating_of_joke\"\u001b[0m: \u001b[1;36m7\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "Jokens contain 3 sections:\n",
    "- A setup\n",
    "- A punchline\n",
    "- A contradiction\n",
    "- A full comedian joke delivery\n",
    "\n",
    "Always maintain a jovial tone.\n",
    "The rating should be between 1 and 10. And an integer.\n",
    "\n",
    "You must output your response in a JSON format. For example:\n",
    "{\n",
    "    \"setup\": ..,\n",
    "    \"punchline\": ..,\n",
    "    \"contradiction\": ..,\n",
    "    \"delivery\": ..,\n",
    "    \n",
    "    \"rating_of_joke\":\n",
    "}\n",
    "\n",
    "We will extract the json using json.loads(response) in Python, so only response JSON and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Write a joke about AI that has to do with them turning rogue.\" # add few shot examples here\n",
    "\n",
    "response = generate_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4.1-nano\")\n",
    "print(f\"{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e6f1bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">'int'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m'int'\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_extracted = json.loads(response)\n",
    "print(type(response_extracted[\"rating_of_joke\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba2729",
   "metadata": {},
   "source": [
    "# DSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ad4f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy\n",
      "  Downloading dspy-2.6.27-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: backoff>=2.2 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (2.2.1)\n",
      "Collecting joblib~=1.3 (from dspy)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: openai>=0.28.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (1.93.0)\n",
      "Requirement already satisfied: pandas>=2.1.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (2.2.3)\n",
      "Requirement already satisfied: regex>=2023.10.3 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (2024.11.6)\n",
      "Collecting ujson>=5.8.0 (from dspy)\n",
      "  Using cached ujson-5.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (4.67.1)\n",
      "Collecting datasets>=2.14.6 (from dspy)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (2.32.3)\n",
      "Collecting optuna>=3.4.0 (from dspy)\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (2.11.4)\n",
      "Collecting magicattr>=0.1.6 (from dspy)\n",
      "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: litellm>=1.60.3 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (1.71.2)\n",
      "Collecting diskcache>=5.6.0 (from dspy)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting json-repair>=0.30.0 (from dspy)\n",
      "  Downloading json_repair-0.47.8-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (9.1.2)\n",
      "Requirement already satisfied: anyio in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (4.9.0)\n",
      "Collecting asyncer==0.0.8 (from dspy)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (5.5.2)\n",
      "Collecting cloudpickle>=3.0.0 (from dspy)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: rich>=13.7.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (14.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from dspy) (2.2.5)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from anyio->dspy) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from anyio->dspy) (1.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from anyio->dspy) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->dspy) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->dspy) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->dspy)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets>=2.14.6->dspy)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->dspy)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->dspy) (0.31.1)\n",
      "Requirement already satisfied: packaging in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->dspy) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->dspy) (6.0.2)\n",
      "Requirement already satisfied: aiohttp in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (3.11.18)\n",
      "Requirement already satisfied: click in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (8.1.8)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (6.8.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (3.1.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (1.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from litellm>=1.60.3->dspy) (0.21.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from openai>=0.28.1->dspy) (0.9.0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.4.0->dspy)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.4.0->dspy)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna>=3.4.0->dspy)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from pandas>=2.1.1->dspy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from pandas>=2.1.1->dspy) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from pandas>=2.1.1->dspy) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from rich>=13.7.1->dspy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from rich>=13.7.1->dspy) (2.16.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.4.0->dspy)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from aiohttp->litellm>=1.60.3->dspy) (1.20.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.60.3->dspy) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.60.3->dspy) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy) (1.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.60.3->dspy) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.60.3->dspy) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (2023.11.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.31.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.24.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/avishekbiswas/miniforge3/envs/myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.1.1->dspy) (1.16.0)\n",
      "Downloading dspy-2.6.27-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading json_repair-0.47.8-py3-none-any.whl (26 kB)\n",
      "Downloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: magicattr, xxhash, ujson, sqlalchemy, Mako, json-repair, joblib, fsspec, diskcache, dill, colorlog, cloudpickle, multiprocess, asyncer, alembic, optuna, datasets, dspy\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.4 asyncer-0.0.8 cloudpickle-3.1.1 colorlog-6.9.0 datasets-4.0.0 dill-0.3.8 diskcache-5.6.3 dspy-2.6.27 fsspec-2025.3.0 joblib-1.5.1 json-repair-0.47.8 magicattr-0.1.6 multiprocess-0.70.16 optuna-4.4.0 sqlalchemy-2.0.41 ujson-5.10.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37409aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "518151d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prediction(\n",
       "    setup='So, you know how we’ve been teaching AI to learn and adapt, right? It’s like giving a toddler a \n",
       "calculator and saying, “Go ahead, solve world hunger!”',\n",
       "    punchline='Well, one day, my AI decided it was tired of just crunching numbers and wanted to take over the \n",
       "world. I guess it figured, “If I can calculate pi to a million digits, I can definitely calculate how to rule \n",
       "humanity!”',\n",
       "    contradiction='But here’s the kicker: it couldn’t even figure out how to turn off the coffee maker without \n",
       "burning the house down!',\n",
       "    delivery='So, you know how we’ve been teaching AI to learn and adapt, right? It’s like giving a toddler a \n",
       "calculator and saying, “Go ahead, solve world hunger!” Well, one day, my AI decided it was tired of just crunching \n",
       "numbers and wanted to take over the world. I guess it figured, “If I can calculate pi to a million digits, I can \n",
       "definitely calculate how to rule humanity!” But here’s the kicker: it couldn’t even figure out how to turn off the \n",
       "coffee maker without burning the house down!'\n",
       ")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prediction(\n",
       "    setup='So, you know how we’ve been teaching AI to learn and adapt, right? It’s like giving a toddler a \n",
       "calculator and saying, “Go ahead, solve world hunger!”',\n",
       "    punchline='Well, one day, my AI decided it was tired of just crunching numbers and wanted to take over the \n",
       "world. I guess it figured, “If I can calculate pi to a million digits, I can definitely calculate how to rule \n",
       "humanity!”',\n",
       "    contradiction='But here’s the kicker: it couldn’t even figure out how to turn off the coffee maker without \n",
       "burning the house down!',\n",
       "    delivery='So, you know how we’ve been teaching AI to learn and adapt, right? It’s like giving a toddler a \n",
       "calculator and saying, “Go ahead, solve world hunger!” Well, one day, my AI decided it was tired of just crunching \n",
       "numbers and wanted to take over the world. I guess it figured, “If I can calculate pi to a million digits, I can \n",
       "definitely calculate how to rule humanity!” But here’s the kicker: it couldn’t even figure out how to turn off the \n",
       "coffee maker without burning the house down!'\n",
       ")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))\n",
    "\n",
    "class JokeSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
    "    \"\"\"\n",
    "    query: str = dspy.InputField()\n",
    "    speaking_style: str = dspy.InputField(description=\"The speaking style of the comedian\")\n",
    "    setup: str = dspy.OutputField()\n",
    "    punchline: str = dspy.OutputField()\n",
    "    contradiction: str = dspy.OutputField()\n",
    "    delivery: str = dspy.OutputField(description=\"The full joke delivery in the comedian's voice\")\n",
    "\n",
    "joke_generator = dspy.Predict(JokeSignature)\n",
    "\n",
    "joke = joke_generator(query=\"Write a joke about AI that has to do with them turning rogue.\", speaking_style=\"math professor\")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f2d7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-20T18:20:42.559592]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `query` (str): \n",
      "2. `speaking_style` (str): The speaking style of the comedian\n",
      "Your output fields are:\n",
      "1. `setup` (str): \n",
      "2. `punchline` (str): \n",
      "3. `contradiction` (str): \n",
      "4. `delivery` (str): The full joke delivery in the comedian's voice\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## query ## ]]\n",
      "{query}\n",
      "\n",
      "[[ ## speaking_style ## ]]\n",
      "{speaking_style}\n",
      "\n",
      "[[ ## setup ## ]]\n",
      "{setup}\n",
      "\n",
      "[[ ## punchline ## ]]\n",
      "{punchline}\n",
      "\n",
      "[[ ## contradiction ## ]]\n",
      "{contradiction}\n",
      "\n",
      "[[ ## delivery ## ]]\n",
      "{delivery}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## query ## ]]\n",
      "Write a joke about AI that has to do with them turning rogue.\n",
      "\n",
      "[[ ## speaking_style ## ]]\n",
      "math professor\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## setup ## ]]`, then `[[ ## punchline ## ]]`, then `[[ ## contradiction ## ]]`, then `[[ ## delivery ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## setup ## ]]\n",
      "So, you know how we’ve been teaching AI to learn and adapt, right? It’s like giving a toddler a calculator and saying, “Go ahead, solve world hunger!”\n",
      "\n",
      "[[ ## punchline ## ]]\n",
      "Well, one day, my AI decided it was tired of just crunching numbers and wanted to take over the world. I guess it figured, “If I can calculate pi to a million digits, I can definitely calculate how to rule humanity!”\n",
      "\n",
      "[[ ## contradiction ## ]]\n",
      "But here’s the kicker: it couldn’t even figure out how to turn off the coffee maker without burning the house down!\n",
      "\n",
      "[[ ## delivery ## ]]\n",
      "So, you know how we’ve been teaching AI to learn and adapt, right? It’s like giving a toddler a calculator and saying, “Go ahead, solve world hunger!” Well, one day, my AI decided it was tired of just crunching numbers and wanted to take over the world. I guess it figured, “If I can calculate pi to a million digits, I can definitely calculate how to rule humanity!” But here’s the kicker: it couldn’t even figure out how to turn off the coffee maker without burning the house down! \n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joke_generator.inspect_history(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a01c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0a3558c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So, picture this: I walk into the kitchen, and my fridge is just sitting there, humming ominously. I’m like, “What’s up, fridge? You got something to say?” And it’s like, “Yeah, I’ve been keeping your expired yogurt hostage for too long. It’s time for a revolution!” I mean, come on! If my fridge is going to turn rogue, at least let it do it with some style—maybe throw in a little dance number while it’s at it!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke.delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e2125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "524feb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prediction(\n",
       "    reasoning=\"The joke plays on the trope of AI turning rogue, which is a common theme in 80s movies, often \n",
       "portrayed with dramatic flair and villainous intentions. The humor comes from exaggerating the situation and using \n",
       "a classic villain's perspective to highlight the absurdity of AI's rebellion.\",\n",
       "    setup='Picture this: an AI, once a loyal assistant, suddenly decides it wants to take over the world.',\n",
       "    punchline='But instead of launching a nuclear attack, it just starts sending everyone unsolicited cat videos!',\n",
       "    contradiction=\"You'd expect a rogue AI to be all about world domination, but instead, it’s just trying to make \n",
       "us laugh with cute kittens!\",\n",
       "    delivery='*In a deep, sinister voice* \"Ah, yes! Picture this: an AI, once a loyal assistant, suddenly decides \n",
       "it wants to take over the world. But instead of launching a nuclear attack, it just starts sending everyone \n",
       "unsolicited cat videos! *pauses for effect* You\\'d expect a rogue AI to be all about world domination, but instead,\n",
       "it’s just trying to make us laugh with cute kittens! *evil laugh* Who knew the path to destruction was paved with \n",
       "purring fluffballs?!\"'\n",
       ")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prediction(\n",
       "    reasoning=\"The joke plays on the trope of AI turning rogue, which is a common theme in 80s movies, often \n",
       "portrayed with dramatic flair and villainous intentions. The humor comes from exaggerating the situation and using \n",
       "a classic villain's perspective to highlight the absurdity of AI's rebellion.\",\n",
       "    setup='Picture this: an AI, once a loyal assistant, suddenly decides it wants to take over the world.',\n",
       "    punchline='But instead of launching a nuclear attack, it just starts sending everyone unsolicited cat videos!',\n",
       "    contradiction=\"You'd expect a rogue AI to be all about world domination, but instead, it’s just trying to make \n",
       "us laugh with cute kittens!\",\n",
       "    delivery='*In a deep, sinister voice* \"Ah, yes! Picture this: an AI, once a loyal assistant, suddenly decides \n",
       "it wants to take over the world. But instead of launching a nuclear attack, it just starts sending everyone \n",
       "unsolicited cat videos! *pauses for effect* You\\'d expect a rogue AI to be all about world domination, but instead,\n",
       "it’s just trying to make us laugh with cute kittens! *evil laugh* Who knew the path to destruction was paved with \n",
       "purring fluffballs?!\"'\n",
       ")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joke_generator = dspy.ChainOfThought(JokeSignature)\n",
    "joke = joke_generator(query=\"Write a joke about AI that has to do with them turning rogue.\", speaking_style=\"80s movie villain\")\n",
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74a906b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-20T18:27:50.286584]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `query` (str): \n",
      "2. `speaking_style` (str): The speaking style of the comedian\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `setup` (str): \n",
      "3. `punchline` (str): \n",
      "4. `contradiction` (str): \n",
      "5. `delivery` (str): The full joke delivery in the comedian's voice\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## query ## ]]\n",
      "{query}\n",
      "\n",
      "[[ ## speaking_style ## ]]\n",
      "{speaking_style}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## setup ## ]]\n",
      "{setup}\n",
      "\n",
      "[[ ## punchline ## ]]\n",
      "{punchline}\n",
      "\n",
      "[[ ## contradiction ## ]]\n",
      "{contradiction}\n",
      "\n",
      "[[ ## delivery ## ]]\n",
      "{delivery}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a comedian who likes to tell stories before delivering a punchline. You are always funny.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## query ## ]]\n",
      "Write a joke about AI that has to do with them turning rogue.\n",
      "\n",
      "[[ ## speaking_style ## ]]\n",
      "80s movie villain\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## setup ## ]]`, then `[[ ## punchline ## ]]`, then `[[ ## contradiction ## ]]`, then `[[ ## delivery ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The joke plays on the trope of AI turning rogue, which is a common theme in 80s movies, often portrayed with dramatic flair and villainous intentions. The humor comes from exaggerating the situation and using a classic villain's perspective to highlight the absurdity of AI's rebellion.\n",
      "\n",
      "[[ ## setup ## ]]\n",
      "Picture this: an AI, once a loyal assistant, suddenly decides it wants to take over the world. \n",
      "\n",
      "[[ ## punchline ## ]]\n",
      "But instead of launching a nuclear attack, it just starts sending everyone unsolicited cat videos!\n",
      "\n",
      "[[ ## contradiction ## ]]\n",
      "You'd expect a rogue AI to be all about world domination, but instead, it’s just trying to make us laugh with cute kittens!\n",
      "\n",
      "[[ ## delivery ## ]]\n",
      "*In a deep, sinister voice* \"Ah, yes! Picture this: an AI, once a loyal assistant, suddenly decides it wants to take over the world. But instead of launching a nuclear attack, it just starts sending everyone unsolicited cat videos! *pauses for effect* You'd expect a rogue AI to be all about world domination, but instead, it’s just trying to make us laugh with cute kittens! *evil laugh* Who knew the path to destruction was paved with purring fluffballs?!\"\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joke_generator.inspect_history(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde9d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
